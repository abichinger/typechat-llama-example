services:
  llama-cpp-python:
    image: ghcr.io/abetlen/llama-cpp-python:latest
    container_name: llama-cpp-python
    restart: unless-stopped
    ports:
      - 8000:8000
    environment:
      - MODEL=/models/llama-2-13b-chat.ggmlv3.q4_0.bin
    volumes:
      - ./models:/models